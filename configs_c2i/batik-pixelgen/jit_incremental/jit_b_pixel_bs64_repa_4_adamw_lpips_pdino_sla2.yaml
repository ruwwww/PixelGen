# lightning.pytorch==2.4.0
# SLA2 (Sparse-Linear Attention with Learnable Routing and QAT) Configuration
# Based on: jit_b_pixel_bs64_repa_4_adamw_lpips_pdino.yaml
# Enhanced with SLA2 attention mechanism for improved efficiency and quality

seed_everything: 1234
tags:
  exp: &exp jit_b_pixel_bs64_repa_4_sla2_lpips_pdino_adamw

huggingface_cache_dir: null

trainer:
  default_root_dir: ./universal_pix_workdirs
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: bf16-mixed
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: jit_b_pixel_ablation_sla2
      name: *exp
  num_sanity_val_steps: 0
  max_steps: 1050000
  val_check_interval: null
  check_val_every_n_epoch: 1000000
  log_every_n_steps: 50
  deterministic: null
  inference_mode: true
  use_distributed_sampler: false
  # Note: Checkpoint starts at step 1M. To fine-tune for 50k additional steps, max_steps = 1050000
  # Override via CLI: --trainer.max_steps 1050000
  callbacks:
    - class_path: src.callbacks.model_checkpoint.CheckpointHook
      init_args:
        every_n_train_steps: 50000
        save_top_k: -1
        save_last: true
    - class_path: src.callbacks.save_images.SaveImagesHook
      init_args:
        save_dir: val_ode50_cfg2.0
        save_compressed: true
    - class_path: src.utils.sla2_training.SLA2TwoStageScheduler
      init_args:
        warmup_steps: 10000
        soft_topk_ratio: 0.20
        hard_topk_ratio: 0.10
        soft_topk_tau: 1.0
        soft_topk_iters: 8
        router_aux_weight_stage1: 1.0
        router_aux_weight_stage2: 0.0
  plugins:
    - src.plugins.bd_env.BDEnvironment

model:
  vae:
    class_path: src.models.autoencoder.pixel.PixelAE
    init_args:
      scale: 1.0
  denoiser:
    class_path: src.models.transformer.JiT_SLA2.JiTSLA2
    init_args:
      input_size: 256
      patch_size: 16
      in_channels: 3
      hidden_size: &hidden_dim 768
      depth: 12
      num_heads: 12
      mlp_ratio: 4.0
      attn_drop: 0.0
      proj_drop: 0.0
      num_classes: &num_classes 20
      bottleneck_dim: 128
      use_bottleneck: true
      in_context_len: 32
      in_context_start: 4
      # SLA2 specific parameters
      use_sla2: true                          # Enable SLA2 attention
      sla2_start_layer: 0                     # Apply SLA2 from layer 0 (all layers)
      sla2_topk_ratio: 0.15                   # Use 15% sparse attention (85% sparsity)
      sla2_compression_ratio: 8.0             # Compress router input by 8x
      sla2_enable_qat: true                   # Enable quantization-aware training
      sla2_router_mode: soft                  # soft for warmup, hard for finetune
      sla2_soft_topk_tau: 1.0                 # SoftTop-k temperature
      sla2_soft_topk_iters: 8                 # SoftTop-k bisection steps
      sla2_router_aux_weight: 1.0             # MSE to full attention (stage 1)
  
  conditioner:
    class_path: src.models.conditioner.class_label.LabelConditioner
    init_args:
      num_classes: *num_classes
  
  diffusion_trainer:
    class_path: src.diffusion.flow_matching.training_repa_JiT_LPIPS_DINO_NoiseGating.REPATrainer
    init_args:
      lognorm_t: true
      encoder:
        class_path: src.models.encoder.DINOv2
        init_args:
          weight_path: ~/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth
      align_layer: 4
      proj_denoiser_dim: *hidden_dim
      proj_hidden_dim: *hidden_dim
      proj_encoder_dim: 768
      null_condition_p: 0.1
      P_mean: -0.8
      P_std: 0.8
      t_eps: 0.05
      scheduler: &scheduler src.diffusion.flow_matching.scheduling.LinearScheduler
      lpips_weight: 0.1
      dino_weight: 0.01
      percept_t_threshold: 0.3
  
  diffusion_sampler:
    class_path: src.diffusion.flow_matching.sampling.HeunSamplerJiT
    init_args:
      exact_henu: true
      num_steps: 50
      guidance: 2.0
      timeshift: 1.0
      guidance_interval_min: 0.1
      guidance_interval_max: 0.9
      scheduler: *scheduler
      w_scheduler: src.diffusion.flow_matching.scheduling.LinearScheduler
      guidance_fn: src.diffusion.base.guidance.simple_guidance_fn
      step_fn: src.diffusion.flow_matching.sampling.ode_step_fn
  
  ema_tracker:
    class_path: src.callbacks.simple_ema.SimpleEMA
    init_args:
      decay: 0.9999
  
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 0.0

data:
  train_dataset:
    class_path: src.data.dataset.imagenet.PixImageNet
    init_args:
      root: /data/batik-256/images/  # Docker mount path
      resolution: 256
  eval_dataset: null
  pred_dataset: null
  train_batch_size: 64
  train_num_workers: 8
  pred_batch_size: 32
  pred_num_workers: 1
